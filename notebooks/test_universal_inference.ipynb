{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Multi-Layer Probe Inference\n",
    "\n",
    "Test notebook for running inference across ALL probes and ALL layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanculo/Desktop/Projects/Cogni_map/brije/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import from src\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.probes.universal_multi_layer_inference import UniversalMultiLayerInferenceEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Engine\n",
    "\n",
    "This loads all 450 probes (45 actions × 10 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_dir = Path.cwd().parent / \"data\" / \"probes_binary\"\n",
    "\n",
    "engine = UniversalMultiLayerInferenceEngine(\n",
    "    probes_base_dir=probes_dir,\n",
    "    model_name=\"google/gemma-3-4b-it\",\n",
    "    device=None,\n",
    "    layer_range=(15, 30) \n",
    "    include_sentiment=True,\n",
    "    sentiment_probes_dir=Path.cwd().parent / \"data\" / \"sentiment\" # Auto-detect\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Text #1: Analytical Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I'm thinking about how to solve this complex problem step by step\"\n",
    "\n",
    "print(f\"Text: {text1}\\n\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 1: Flat ranked list (top 20 across ALL layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = engine.predict_all(text1, threshold=0.00001, top_k=20)\n",
    "\n",
    "print(\"Top 20 predictions across all layers:\\n\")\n",
    "for i, pred in enumerate(preds, 1):\n",
    "    marker = \"✓\" if pred.is_active else \" \"\n",
    "    print(f\"  {marker} {i:2d}. {pred.action_name:30s} (Layer {pred.layer:2d})  {pred.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 2: By action (max confidence across layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_preds = engine.predict_by_action(text1, threshold=0.1, aggregation=\"max\")\n",
    "\n",
    "print(\"Top 10 actions (max confidence across layers):\\n\")\n",
    "for i, (action_name, data) in enumerate(list(action_preds.items())[:10], 1):\n",
    "    if data['is_active']:\n",
    "        best_layer = data['best_layer']\n",
    "        aggregate = data['aggregate']\n",
    "        \n",
    "        # Show top 3 layers for this action\n",
    "        layer_confs = sorted(data['confidences'].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        layer_str = \", \".join([f\"L{l}:{c:.3f}\" for l, c in layer_confs])\n",
    "        \n",
    "        print(f\"  {i:2d}. {action_name:30s} max={aggregate:.4f} @ Layer {best_layer}\")\n",
    "        print(f\"      Active layers: {layer_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 3: By layer (which actions fire at each depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_preds = engine.predict_by_layer(text1, threshold=0.1)\n",
    "\n",
    "print(\"Predictions grouped by layer (top 3 actions per layer):\\n\")\n",
    "for layer, preds in layer_preds.items():\n",
    "    if preds:\n",
    "        print(f\"\\n  Layer {layer} ({len(preds)} active actions):\")\n",
    "        for j, pred in enumerate(preds[:3], 1):\n",
    "            print(f\"    {j}. {pred.action_name:30s} {pred.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Text #2: Reflection/Metacognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Looking back on my decision, I realize I should have considered other options\"\n",
    "\n",
    "print(f\"Text: {text2}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "preds2 = engine.predict_all(text2, threshold=0.1, top_k=15)\n",
    "\n",
    "print(\"\\nTop 15 predictions:\\n\")\n",
    "for i, pred in enumerate(preds2, 1):\n",
    "    marker = \"✓\" if pred.is_active else \" \"\n",
    "    print(f\"  {marker} {i:2d}. {pred.action_name:30s} (Layer {pred.layer:2d})  {pred.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Text #3: Empathy/Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"I feel deeply moved by their story and want to help them\"\n",
    "\n",
    "print(f\"Text: {text3}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "preds3 = engine.predict_all(text3, threshold=0.1, top_k=15)\n",
    "\n",
    "print(\"\\nTop 15 predictions:\\n\")\n",
    "for i, pred in enumerate(preds3, 1):\n",
    "    marker = \"✓\" if pred.is_active else \" \"\n",
    "    print(f\"  {marker} {i:2d}. {pred.action_name:30s} (Layer {pred.layer:2d})  {pred.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Two Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = engine.compare_texts(text1, text2, top_k=10)\n",
    "\n",
    "print(\"Biggest differences between Text 1 and Text 2:\\n\")\n",
    "for i, diff in enumerate(comparison['biggest_differences'], 1):\n",
    "    action = diff['action']\n",
    "    t1_conf = diff['text1_confidence']\n",
    "    t2_conf = diff['text2_confidence']\n",
    "    delta = diff['difference']\n",
    "    \n",
    "    arrow = \"↑\" if delta > 0 else \"↓\"\n",
    "    \n",
    "    print(f\"  {i:2d}. {action:30s} {arrow} {abs(delta):.4f}  (Text1: {t1_conf:.3f}, Text2: {t2_conf:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Try your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this text to test your own examples\n",
    "custom_text = \"Your text here...\"\n",
    "\n",
    "preds = engine.predict_all(custom_text, threshold=0.1, top_k=15)\n",
    "\n",
    "print(f\"Text: {custom_text}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTop 15 predictions:\\n\")\n",
    "for i, pred in enumerate(preds, 1):\n",
    "    marker = \"✓\" if pred.is_active else \" \"\n",
    "    print(f\"  {marker} {i:2d}. {pred.action_name:30s} (Layer {pred.layer:2d})  {pred.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Cross-Layer Patterns for Specific Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an action to analyze in detail\n",
    "target_action = \"reasoning\"  # Change this to any cognitive action\n",
    "\n",
    "text = \"I'm thinking about how to solve this complex problem step by step\"\n",
    "\n",
    "action_preds = engine.predict_by_action(text, threshold=0.0, aggregation=\"all\")\n",
    "\n",
    "if target_action in action_preds:\n",
    "    data = action_preds[target_action]\n",
    "    print(f\"Cross-layer analysis for '{target_action}':\\n\")\n",
    "    print(f\"Text: {text}\\n\")\n",
    "    \n",
    "    # Sort by layer\n",
    "    layer_confs = sorted(data['confidences'].items())\n",
    "    \n",
    "    print(\"Confidence across layers:\")\n",
    "    for layer, conf in layer_confs:\n",
    "        bar = \"█\" * int(conf * 50)\n",
    "        print(f\"  Layer {layer:2d}: {conf:.4f} {bar}\")\n",
    "    \n",
    "    print(f\"\\nBest layer: {data['best_layer']}\")\n",
    "    print(f\"Max confidence: {max(data['confidences'].values()):.4f}\")\n",
    "    print(f\"Mean confidence: {sum(data['confidences'].values()) / len(data['confidences']):.4f}\")\n",
    "else:\n",
    "    print(f\"Action '{target_action}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing: Multiple Texts\n",
    "\n",
    "Add as many texts as you want to test in bulk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Add your test strings here\n",
    "test_strings = [\n",
    "    \"The quarterly numbers look... interesting. Revenue up 12%, but margins down 3%. Customer acquisition costs rising while retention rates plateau. Something doesn't add up here.\",\n",
    "    \"What if we completely flipped the script? Instead of chasing the same customers everyone else wants, what about targeting the segment nobody's paying attention to?\",\n",
    "    \"Last quarter's campaign... we spent $50K on social media ads, got 200 signups, but only 15 converted. That's a 7.5% conversion rate. Industry average is 12%. We're bleeding money.\",\n",
    "    \"That client meeting keeps replaying in my head. Sarah said 'the integration feels clunky' and I brushed it off. Now three clients have mentioned the same thing. I should have listened.\",\n",
    "    \"My brain is scattered. Need to organize this mess: finish the Q4 budget review, prep for tomorrow's board meeting, and draft the hiring plan for next quarter. Otherwise I'll forget something crucial.\",\n",
    "    \"Where are we on the Johnson account? Last I heard, legal was reviewing the contract. Marketing said they'd have the campaign ready by Friday. Finance needs the numbers by end of week. Everything's converging.\",\n",
    "    \"Client feedback from Project Alpha, user research from Beta, and market analysis from Gamma. All pointing in different directions. There's a pattern here I'm not seeing yet.\",\n",
    "    \"Option A: expand to Europe, higher risk but potentially 40% revenue growth. Option B: focus on domestic market, safer but maybe 15% growth. Both have merit. Both have downsides.\",\n",
    "    \"The website keeps crashing during peak hours. Server logs show increased traffic, but that shouldn't cause failures. There's something else going on.\",\n",
    "    \"The interns are lost. I'm throwing terms like 'conversion funnel' and 'attribution modeling' at them. They need the basics first - what we're trying to achieve and why.\",\n",
    "    \"This product launch strategy feels incomplete. Maybe I should bounce ideas off the team. Fresh perspectives could reveal blind spots I'm missing.\",\n",
    "    \"I've been assuming our target demographic is 25-35 year olds. But what if that's wrong? What if I'm basing decisions on outdated assumptions?\",\n",
    "    \"This dashboard is overwhelming. Revenue charts, user engagement metrics, conversion rates, churn analysis. Too much noise. Need to focus on what actually matters.\",\n",
    "    \"The current approach isn't working. Users aren't engaging with the new feature. Maybe we need to pivot. Try a different angle entirely.\",\n",
    "    \"These customer segments look similar on paper - both tech-savvy, both high income. But their behavior patterns are completely different. What am I missing?\",\n",
    "    \"If we launch in Q2 instead of Q1, we'd have more time for testing. But competitors might beat us to market. If we rush Q1, we risk bugs. If we wait, we risk irrelevance.\",\n",
    "    \"The manager's email was vague: 'streamline the process.' What does that mean exactly? Reduce steps? Automate tasks? Cut costs? Need to clarify before I act.\",\n",
    "    \"I'm recommending we increase the marketing budget by 30%. But why? Because last quarter's campaign worked? Because competitors are spending more? Need solid reasoning.\",\n",
    "    \"Sally flagged that our pricing model doesn't account for seasonal fluctuations. She's right. Our revenue projections assume steady demand year-round. That's unrealistic.\",\n",
    "    \"The project timeline is chaotic. Phase 1 should inform Phase 2, which should inform Phase 3. But everything's happening simultaneously. Need to map out dependencies.\",\n",
    "    \"This market research feels biased. The methodology seems sound, but the conclusions feel predetermined. Like they found what they were looking for.\",\n",
    "    \"The correlation between social media engagement and sales is strong. But that doesn't mean social media causes sales. Could be reverse causation, or a third factor entirely.\",\n",
    "    \"Let's test this hypothesis: if our target users really want this feature, they'll use it within the first week. If not, we'll know it's not solving a real problem.\",\n",
    "    \"Both theories explain the data well. Theory A focuses on user behavior, Theory B on market conditions. They're not mutually exclusive, but they emphasize different factors.\",\n",
    "    \"This industry report cites impressive statistics, but I don't recognize the research firm. Need to verify their credibility before I base any decisions on their findings.\",\n",
    "    \"Today's priorities are overwhelming. The client presentation, the budget review, the team meeting, the product demo. Can't do everything. Need to pick what's truly urgent.\",\n",
    "    \"The alternative approach might be better. Current method is familiar, but the new one could be more efficient. Should we compare them side by side before deciding?\",\n",
    "    \"Let me explain this simply: we're not making money because we're spending more to acquire customers than we earn from them. Like buying a $10 item for $15.\",\n",
    "    \"I remember being overwhelmed by all these metrics and KPIs when I started. Jamie looks lost in the same way. Maybe I can help them understand what actually matters.\",\n",
    "    \"Sitting here watching people interact with our app. Some scroll quickly, others pause and tap. Some get frustrated and leave. Others seem to find what they need. Patterns emerging.\"\n",
    "]\n",
    "\n",
    "threshold = 0.1\n",
    "display_threshold = 0.001  # Only show actions with confidence >= 0.001\n",
    "\n",
    "print(f\"Processing {len(test_strings)} texts...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, text in enumerate(test_strings, 1):\n",
    "    print(f\"\\n[{i}/{len(test_strings)}] Text:\")\n",
    "    print(f'\"{text}\"')\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Get predictions organized by layer\n",
    "    layer_preds = engine.predict_by_layer(text, threshold=threshold)\n",
    "    \n",
    "    if layer_preds:\n",
    "        # Display results for each layer (21-30)\n",
    "        for layer in range(21, 31):\n",
    "            preds = layer_preds.get(layer, [])\n",
    "            if preds:\n",
    "                # Filter by display threshold and format actions with confidences\n",
    "                filtered_preds = [p for p in preds if p.confidence >= display_threshold]\n",
    "                if filtered_preds:\n",
    "                    actions_str = \", \".join([f\"{p.action_name}({p.confidence:.3f})\" for p in filtered_preds])\n",
    "                    print(f\"  Layer {layer:2d}: {actions_str}\")\n",
    "    else:\n",
    "        print(\"  No predictions above threshold\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Batch testing complete: {len(test_strings)} texts processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing with Summary Statistics\n",
    "\n",
    "Process multiple texts and get aggregate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many test strings as you want here!\n",
    "test_strings = [\n",
    "    \"I'm thinking about how to solve this problem\",\n",
    "    \"Looking back, I should have done things differently\",\n",
    "    \"I feel empathy for their situation\",\n",
    "    \"This reminds me of a similar situation from before\",\n",
    "    \"Let me break this down into smaller parts\",\n",
    "    \"I need to understand the underlying principles\",\n",
    "    \"What if we tried a completely different approach?\",\n",
    "    \"I'm comparing these two options carefully\",\n",
    "    # Add more strings here...\n",
    "]\n",
    "\n",
    "# Settings\n",
    "threshold = 0.1\n",
    "top_k_per_text = 5  # Show top 5 predictions per text\n",
    "\n",
    "print(f\"Testing {len(test_strings)} texts\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Process each text\n",
    "for i, text in enumerate(test_strings, 1):\n",
    "    print(f\"\\n[{i}/{len(test_strings)}] Text: \\\"{text}\\\"\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = engine.predict_all(text, threshold=threshold, top_k=top_k_per_text)\n",
    "    \n",
    "    if preds:\n",
    "        print(f\"Top {len(preds)} predictions:\")\n",
    "        for j, pred in enumerate(preds, 1):\n",
    "            marker = \"✓\" if pred.is_active else \" \"\n",
    "            print(f\"  {marker} {j}. {pred.action_name:25s} (L{pred.layer:2d}) {pred.confidence:.4f}\")\n",
    "    else:\n",
    "        print(\"  No predictions above threshold\")\n",
    "    \n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Batch testing complete: {len(test_strings)} texts processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
